{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "train = pd.read_csv('train.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_filename</th>\n",
       "      <th>lighting</th>\n",
       "      <th>city</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame_20f328fa-2459-46d0-97a5-5ae2d6103cb0_000...</td>\n",
       "      <td>Twilight</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame_927bde20-f97f-48c2-af30-f9127b6b32ce_000...</td>\n",
       "      <td>Day</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame_67012509-f3bd-4175-a9d2-565a7b6bb3c7_000...</td>\n",
       "      <td>Day</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frame_bd043377-6fb8-407a-95e5-7deb1fbab13a_000...</td>\n",
       "      <td>Day</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frame_4da1583b-58d0-4893-8149-54541191031d_000...</td>\n",
       "      <td>Day</td>\n",
       "      <td>NYC</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image_filename  lighting city\n",
       "0  frame_20f328fa-2459-46d0-97a5-5ae2d6103cb0_000...  Twilight  NYC\n",
       "1  frame_927bde20-f97f-48c2-af30-f9127b6b32ce_000...       Day  NYC\n",
       "2  frame_67012509-f3bd-4175-a9d2-565a7b6bb3c7_000...       Day  NYC\n",
       "3  frame_bd043377-6fb8-407a-95e5-7deb1fbab13a_000...       Day  NYC\n",
       "4  frame_4da1583b-58d0-4893-8149-54541191031d_000...       Day  NYC"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_boxes = pd.read_csv('train_boxes.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>image_filename</th>\n",
       "      <th>x0</th>\n",
       "      <th>y0</th>\n",
       "      <th>x1</th>\n",
       "      <th>y1</th>\n",
       "      <th>label</th>\n",
       "      <th>confidence</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>frame_817c47b8-22c4-438a-8dc6-0e3f67f299ee_000...</td>\n",
       "      <td>601.600000</td>\n",
       "      <td>270.355731</td>\n",
       "      <td>726.755556</td>\n",
       "      <td>421.185771</td>\n",
       "      <td>van</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>frame_817c47b8-22c4-438a-8dc6-0e3f67f299ee_000...</td>\n",
       "      <td>497.777778</td>\n",
       "      <td>308.774704</td>\n",
       "      <td>534.755556</td>\n",
       "      <td>338.656126</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>frame_817c47b8-22c4-438a-8dc6-0e3f67f299ee_000...</td>\n",
       "      <td>449.422222</td>\n",
       "      <td>310.197628</td>\n",
       "      <td>509.155556</td>\n",
       "      <td>358.577075</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>frame_a9110bf2-5252-4ec6-83c6-33b65d0fc04d_000...</td>\n",
       "      <td>711.111111</td>\n",
       "      <td>304.505929</td>\n",
       "      <td>786.488889</td>\n",
       "      <td>368.537549</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>frame_a9110bf2-5252-4ec6-83c6-33b65d0fc04d_000...</td>\n",
       "      <td>584.533333</td>\n",
       "      <td>307.351779</td>\n",
       "      <td>647.111111</td>\n",
       "      <td>358.577075</td>\n",
       "      <td>car</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                      image_filename          x0          y0  \\\n",
       "0  frame_817c47b8-22c4-438a-8dc6-0e3f67f299ee_000...  601.600000  270.355731   \n",
       "1  frame_817c47b8-22c4-438a-8dc6-0e3f67f299ee_000...  497.777778  308.774704   \n",
       "2  frame_817c47b8-22c4-438a-8dc6-0e3f67f299ee_000...  449.422222  310.197628   \n",
       "3  frame_a9110bf2-5252-4ec6-83c6-33b65d0fc04d_000...  711.111111  304.505929   \n",
       "4  frame_a9110bf2-5252-4ec6-83c6-33b65d0fc04d_000...  584.533333  307.351779   \n",
       "\n",
       "           x1          y1 label  confidence  \n",
       "0  726.755556  421.185771   van         1.0  \n",
       "1  534.755556  338.656126   car         1.0  \n",
       "2  509.155556  358.577075   car         1.0  \n",
       "3  786.488889  368.537549   car         1.0  \n",
       "4  647.111111  358.577075   car         1.0  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_boxes[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Counter({1.0: 134361})"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "Counter(train_boxes['confidence'].ravel())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_boxes.drop(labels = 'confidence', axis = 1, inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_names, test_names = train_test_split(train.image_filename.values, test_size = 0.1, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full = train_boxes.merge(train, on = 'image_filename')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "full_train = full[full.image_filename.isin(train_names)]\n",
    "full_validation = full[full.image_filename.isin(test_names)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((134361, 6), (120918, 8), (13443, 8))"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_boxes.shape, full_train.shape, full_validation.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OpenCV baseline (no tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--2017-08-12 10:59:39--  https://raw.githubusercontent.com/Juzer2012/Car-detection/master/cars.xml\n",
      "Resolving raw.githubusercontent.com (raw.githubusercontent.com)... 151.101.12.133\n",
      "Connecting to raw.githubusercontent.com (raw.githubusercontent.com)|151.101.12.133|:443... connected.\n",
      "HTTP request sent, awaiting response... 200 OK\n",
      "Length: 118803 (116K) [text/plain]\n",
      "Saving to: ‘cars.xml’\n",
      "\n",
      "cars.xml            100%[===================>] 116,02K   662KB/s    in 0,2s    \n",
      "\n",
      "2017-08-12 10:59:40 (662 KB/s) - ‘cars.xml’ saved [118803/118803]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "!wget https://raw.githubusercontent.com/Juzer2012/Car-detection/master/cars.xml -O cars.xml"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import cv2\n",
    " \n",
    "car_cascade = cv2.CascadeClassifier('cars.xml')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "#Adopted from @bendyna code \n",
    "def get_predictions(image_filenames):\n",
    "    result = []\n",
    "    for image_file in tqdm(image_filenames):\n",
    "        path = os.path.join('images', image_file)\n",
    "        image = cv2.imread(path)\n",
    "        if image is None:\n",
    "            continue\n",
    "        cars = car_cascade.detectMultiScale(image, 1.1, 2)\n",
    "\n",
    "        prediction_boxes = []\n",
    "        for x, y, w, h in cars:\n",
    "            box = (x, y, x + w, y + h)\n",
    "            prediction_boxes.append((random.random(), box))\n",
    "            \n",
    "        true_boxes = []\n",
    "        for _, row in train_boxes[train_boxes.image_filename == image_file].iterrows():\n",
    "            true_boxes.append((row.x0, row.y0, row.x1, row.y1))\n",
    "        result.append((image_file, true_boxes, prediction_boxes))\n",
    "    \n",
    "    print len(result)\n",
    "    return result\n",
    "\n",
    "def IOU(box1, box2):\n",
    "    left = max(box1[0], box2[0])\n",
    "    top = max(box1[1], box2[1])\n",
    "    right = min(box1[2], box2[2])\n",
    "    bottom = min(box1[3], box2[3])\n",
    "    w = max(0, right - left + 1)\n",
    "    h = max(0, bottom - top + 1)\n",
    "    inter = w * h\n",
    "    uni = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1) \\\n",
    "            + (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1) - inter\n",
    "    return inter * 1. / uni\n",
    "\n",
    "\n",
    "def average_precision(arr, iou_threshold=0.75):\n",
    "    score_detection = []\n",
    "    all_true = 0\n",
    "    for _, true_boxes, prediction_boxes in arr:\n",
    "        all_true += len(true_boxes)\n",
    "        detected = [0] * len(true_boxes)\n",
    "        pboxes = sorted(prediction_boxes, key=lambda x: x[0], reverse=True)\n",
    "        for score, box in pboxes:\n",
    "            best = None\n",
    "            best_iou = 0\n",
    "            for i in range(len(true_boxes)):\n",
    "                if detected[i]:\n",
    "                    continue\n",
    "                iou = IOU(true_boxes[i], box)\n",
    "                if iou >= iou_threshold and iou > best_iou:\n",
    "                    best, best_iou = i, iou\n",
    "            if best is not None:\n",
    "                detected[i] = 1\n",
    "                score_detection.append((score, 1))\n",
    "            else:\n",
    "                score_detection.append((score, 0))\n",
    "    score_detection = sorted(score_detection, key=lambda x: x[0], reverse=True)\n",
    "    result = 0\n",
    "    width = 1. / all_true\n",
    "    height = 1\n",
    "    count = 0\n",
    "    count1 = 0\n",
    "    for score, detection in score_detection:\n",
    "        count += 1\n",
    "        if detection:\n",
    "            result += width * height\n",
    "            count1 += 1\n",
    "        else:\n",
    "            height = count1 * 1.0 / count\n",
    "    return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 250/250 [00:25<00:00,  9.62it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "250\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision(get_predictions(test_names[::20]), 0.75)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SSD (No tuning)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import keras\n",
    "from keras.applications.imagenet_utils import preprocess_input\n",
    "from keras.backend.tensorflow_backend import set_session\n",
    "from keras.models import Model\n",
    "from keras.preprocessing import image\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "from scipy.misc import imread\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fatal: destination path 'ssd_keras' already exists and is not an empty directory.\r\n"
     ]
    }
   ],
   "source": [
    "!git clone https://github.com/rykov8/ssd_keras.git"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "!touch ssd_keras/__init__.py"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {
    "scrolled": false
   },
   "source": [
    "!cat ssd_keras/ssd.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from ssd_keras.ssd import SSD300\n",
    "from ssd_keras.ssd_utils import BBoxUtility\n",
    "\n",
    "%matplotlib inline\n",
    "plt.rcParams['figure.figsize'] = (8, 8)\n",
    "plt.rcParams['image.interpolation'] = 'nearest'\n",
    "\n",
    "np.set_printoptions(suppress=True)\n",
    "\n",
    "config = tf.ConfigProto()\n",
    "config.gpu_options.per_process_gpu_memory_fraction = 0.95\n",
    "set_session(tf.Session(config=config))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "voc_classes = ['Aeroplane', 'Bicycle', 'Bird', 'Boat', 'Bottle',\n",
    "               'Bus', 'Car', 'Cat', 'Chair', 'Cow', 'Diningtable',\n",
    "               'Dog', 'Horse','Motorbike', 'Person', 'Pottedplant',\n",
    "               'Sheep', 'Sofa', 'Train', 'Tvmonitor']\n",
    "NUM_CLASSES = len(voc_classes) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gt_pascal.pkl  pics\t\t       ssd_layers.pyc\t   ssd_utils.py\r\n",
      "__init__.py    prior_boxes_ssd300.pkl  ssd.py\t\t   ssd_utils.pyc\r\n",
      "__init__.pyc   README.md\t       ssd.pyc\t\t   testing_utils\r\n",
      "LICENSE        SSD.ipynb\t       SSD_training.ipynb  weights_SSD300.hdf5\r\n",
      "PASCAL_VOC     ssd_layers.py\t       ssd_training.py\r\n"
     ]
    }
   ],
   "source": [
    "!ls ssd_keras/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Download weights from https://mega.nz/#F!7RowVLCL!q3cEVRK9jyOSB9el3SssIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_shape=(300, 300, 3)\n",
    "model = SSD300(input_shape, num_classes=NUM_CLASSES)\n",
    "model.load_weights('ssd_keras/weights_SSD300.hdf5', by_name=True)\n",
    "bbox_util = BBoxUtility(NUM_CLASSES)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import random\n",
    "import os\n",
    "from tqdm import tqdm \n",
    "\n",
    "def get_predictions(image_filenames):\n",
    "    result = []\n",
    "\n",
    "    for image_file in tqdm(image_filenames):\n",
    "        path = os.path.join('images', image_file)\n",
    "        try:\n",
    "            img = image.load_img(path)\n",
    "            original_width, original_height = img.size\n",
    "            img = image.load_img(path, target_size=(300, 300))\n",
    "        except IOError:\n",
    "            continue\n",
    "        img = image.img_to_array(img)\n",
    "        \n",
    "        preds = model.predict(np.array([img]), batch_size=1, verbose=False)\n",
    "        prediction_boxes = []\n",
    "        results = bbox_util.detection_out(preds)\n",
    "\n",
    "        for label, conf, xmin, ymin, xmax, ymax in results[0]:\n",
    "            if label in [6]:\n",
    "                box = (xmin * original_width, ymin * original_height, xmax * original_width, ymax * original_height)\n",
    "                prediction_boxes.append((conf, box))\n",
    "            \n",
    "        true_boxes = []\n",
    "        for _, row in train_boxes[train_boxes.image_filename == image_file].iterrows():\n",
    "            true_boxes.append((row.x0, row.y0, row.x1, row.y1))\n",
    "        result.append((image_file, true_boxes, prediction_boxes))\n",
    "    \n",
    "    print len(result)\n",
    "    return result\n",
    "\n",
    "def IOU(box1, box2):\n",
    "    left = max(box1[0], box2[0])\n",
    "    top = max(box1[1], box2[1])\n",
    "    right = min(box1[2], box2[2])\n",
    "    bottom = min(box1[3], box2[3])\n",
    "    w = max(0, right - left + 1)\n",
    "    h = max(0, bottom - top + 1)\n",
    "    inter = w * h\n",
    "    uni = (box1[2] - box1[0] + 1) * (box1[3] - box1[1] + 1) \\\n",
    "            + (box2[2] - box2[0] + 1) * (box2[3] - box2[1] + 1) - inter\n",
    "    return inter * 1. / uni\n",
    "\n",
    "\n",
    "def average_precision(arr, iou_threshold=0.75):\n",
    "    score_detection = []\n",
    "    all_true = 0\n",
    "    for _, true_boxes, prediction_boxes in arr:\n",
    "        all_true += len(true_boxes)\n",
    "        detected = [0] * len(true_boxes)\n",
    "        pboxes = sorted(prediction_boxes, key=lambda x: x[0], reverse=True)\n",
    "        for score, box in pboxes:\n",
    "            best = None\n",
    "            best_iou = 0\n",
    "            for i in range(len(true_boxes)):\n",
    "                if detected[i]:\n",
    "                    continue\n",
    "                iou = IOU(true_boxes[i], box)\n",
    "                if iou >= iou_threshold and iou > best_iou:\n",
    "                    best, best_iou = i, iou\n",
    "            if best is not None:\n",
    "                detected[i] = 1\n",
    "                score_detection.append((score, 1))\n",
    "            else:\n",
    "                score_detection.append((score, 0))\n",
    "    score_detection = sorted(score_detection, key=lambda x: x[0], reverse=True)\n",
    "    result = 0\n",
    "    width = 1. / all_true\n",
    "    height = 1\n",
    "    count = 0\n",
    "    count1 = 0\n",
    "    for score, detection in score_detection:\n",
    "        count += 1\n",
    "        if detection:\n",
    "            result += width * height\n",
    "            count1 += 1\n",
    "        else:\n",
    "            height = count1 * 1.0 / count\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 500/500 [00:32<00:00, 15.27it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.011451336754688584"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "average_precision(get_predictions(test_names[::10]), 0.75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
